{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_2dunet_109uc.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9ZCuLO6CXd4ah+ntAw7p4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nFNM6e8vwXfI"},"source":["## Iteration - 2\r\n","\r\n","This iteration trains a 2d U-net on all the 108 Uchicago scans. "]},{"cell_type":"code","metadata":{"id":"Obuen_iiu_LG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610087801189,"user_tz":360,"elapsed":19291,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"2926fc85-167b-4beb-fcf3-b7585cac6b46"},"source":["from google.colab import drive\r\n","drive.mount(\"/content/drive\")\r\n","\r\n","import os\r\n","import pandas as pd\r\n","import datetime\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CjViHtx25Soq"},"source":["os.chdir('/content/drive/MyDrive/01_eom_segmentation/02_training/03_2dunet_108uc_coronal/')\r\n","os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXXyUqUAKze2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609791307536,"user_tz":360,"elapsed":7074,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"18002b68-f060-4dd6-d796-ffad104dd8fd"},"source":["#%tensorflow_version 1.x\r\n","import tensorflow\r\n","print(tensorflow.__version__)\r\n","\r\n","import keras\r\n","\r\n","!python --version\r\n","\r\n","print(tensorflow.__version__)\r\n","print(keras.__version__)\r\n","\r\n","# Load the TensorBoard notebook extension\r\n","%load_ext tensorboard"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.4.0\n","Python 3.6.9\n","2.4.0\n","2.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jSAl1UAAybkt","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"error","timestamp":1610088576661,"user_tz":360,"elapsed":589,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"9602062e-066f-4b7f-ec12-b17f9b2e69e9"},"source":["from helpers.data import *\r\n","from helpers.datagenerator import *\r\n","from helpers.model import *\r\n","from helpers.visualize import *"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-34c1dd38e651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatagenerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"97Np8RmK5Gp1"},"source":["data_folder='../compiled_npys'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"rpkmPVql6wG0","executionInfo":{"status":"error","timestamp":1610088558164,"user_tz":360,"elapsed":448,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"d954f2ae-a7a2-4ce0-cec6-f7936966f88b"},"source":["'''\r\n","Smaller batch size performs better - Tried with 200 batches but try with 20 maybe for better generalization\r\n","Higher patch size performs better - already tried with 64 patch size, try with 96 or 80 \r\n","Multi-class tends to perform better - try 1 class and 4 class - 1 class better than multi\r\n","One-Zero weights - balanced tends to converge faster - But 0.9 and 0.1 work well in training but don't generalize so well \r\n","WBCE loss seems to work best with SGD with momentum - try other losses with other optimizers - there is one loss that combines wbce and dice too. \r\n","SGD with Momentum seems to work best - other optimizers can be tried. For optimizers with adaptive learning rate, we need to use higher initial LRs, and for SGD we need to use lower learning rate. Nothing else apart from SGD with momentum worked\r\n","LR schedule - exponential decay works well, but you can also try ReduceLROnPlateau callback in keras\r\n","Weight initializers - GlorotUniform seems to work well. \r\n","\r\n","Cosine decay with warm restarts\r\n","Use pydensecrf to post-process output\r\n","\r\n","'''\r\n","\r\n","\r\n","# Initialize Hyperparameters\r\n","\r\n","# Image size\r\n","#IMG_SIZE=64                                         # multiple of 32 (2^depth - unet depth 5 will need atleast 32)\r\n","IMG_SIZE=80                                         # multiple of 32 (2^depth - unet depth 5 will need atleast 32)\r\n","#IMG_SIZE=96                                         # multiple of 32 (2^depth - unet depth 5 will need atleast 32)\r\n","\r\n","# 3D vs 2D \r\n","patch_sz=(IMG_SIZE, IMG_SIZE)\r\n","\r\n","# 2D view-plane\r\n","view_plane_2d='2d'                                  # 'coronal', 'axial', 'sagittal', '3d'\r\n","muscles='all'                                       # 'all', 'mediallateral', 'superiorinferior'\r\n","\r\n","# Set unet depth\r\n","\r\n","\r\n","unet_depth='na'\r\n","\r\n","#n_classes=1                                         # 4 if all; 2 if mediallateral, superiorinferior\r\n","n_classes=4                                         # 4 if all; 2 if mediallateral, superiorinferior\r\n","\r\n","num_scans_in_batch=4\r\n","#num_scans_in_batch=2\r\n","\r\n","#num_patches_in_batch=200                            # keep below 20 for 3d patches and around 100-200 for 2D ; NEEDS TO BE A MULTIPLE OF 4\r\n","num_patches_in_batch=100                            # keep below 20 for 3d patches and around 100-200 for 2D \r\n","#num_patches_in_batch=50                            # keep below 20 for 3d patches and around 100-200 for 2D \r\n","\r\n","n_filters_start = 'na'                                # Unet standard is 64, can try others\r\n","\r\n","\r\n","num_epochs=500\r\n","#num_epochs=2\r\n","\r\n","#LR=3e-5\r\n","#LR=3e-4     # Check first for adam\r\n","LR=0.005   # This worked really well for SGD with momentum\r\n","#LR=0.05\r\n","#LR=0.1\r\n","\r\n","# Windowing settings\r\n","window_center=0\r\n","window_width=400                                    # This is decided from intensity graphs\r\n","\r\n","# Set loss function\r\n","weighted_binary_crossentropy = create_weighted_binary_crossentropy(zero_weight=0.3, one_weight=0.7)\r\n","\r\n","#loss_function=\"focal\"\r\n","#training_loss=focal_tversky\r\n","#loss_function=\"wbce\"                                # \"dice\" or \"focal\" - use focal tversky loss; dice loss is non-convex. \r\n","#training_loss=weighted_binary_crossentropy          # \"dice_coef_loss\" or \"focal_tversky\"\r\n","#loss_function=\"dice\"                               # \"dice\" or \"focal\" - use focal tversky loss; dice loss is non-convex. \r\n","#training_loss=dice_coef_loss                       # \"dice_coef_loss\" or \"focal_tversky\"\r\n","loss_function=\"dice_wbce_loss\"                      # \"dice\" or \"focal\" - use focal tversky loss; dice loss is non-convex. \r\n","training_loss=dice_wbce_loss                        # \"dice_coef_loss\" or \"focal_tversky\"\r\n","\r\n","\r\n","monitoring_loss=training_loss.__name__\r\n","\r\n","# Model architecture\r\n","network='unet_2d'                                   # unet, fpn, linknet, pspnet\r\n","backbone='unet' #    'mobilenetv2'                  # https://github.com/qubvel/segmentation_models\r\n","model_architecture=network+'_'+backbone\r\n","\r\n","print(\"In this iteration we are training a \"+\r\n","      str(model_architecture)+\" model with \"+\r\n","      loss_function+\" loss function to predict \"+\r\n","      str(n_classes)+\" \"+\r\n","      muscles+\" muscles on \"+\r\n","      view_plane_2d+\" slices\")\r\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ca8e781e335a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Set loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mweighted_binary_crossentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_weighted_binary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"focal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_weighted_binary_crossentropy' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVLxIJUf5o7_","executionInfo":{"status":"ok","timestamp":1609736371540,"user_tz":360,"elapsed":8736,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"3403ec82-14a6-40d3-db6a-ebf7ca656dd8"},"source":["#unet=unet2d(input_size = (IMG_SIZE,IMG_SIZE,1), n_classes=n_classes)\r\n","unet=unet_2d_model_deep4(n_classes=n_classes, im_sz=IMG_SIZE, n_channels=1, n_filters_start=100, growth_factor=2, upconv=True)\r\n","unet.summary(line_length=150)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","______________________________________________________________________________________________________________________________________________________\n","Layer (type)                                     Output Shape                     Param #           Connected to                                      \n","======================================================================================================================================================\n","input_1 (InputLayer)                             [(None, 80, 80, 1)]              0                                                                   \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization (BatchNormalization)         (None, 80, 80, 1)                4                 input_1[0][0]                                     \n","______________________________________________________________________________________________________________________________________________________\n","conv2d (Conv2D)                                  (None, 80, 80, 100)              900               batch_normalization[0][0]                         \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_1 (BatchNormalization)       (None, 80, 80, 100)              400               conv2d[0][0]                                      \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_1 (Conv2D)                                (None, 80, 80, 100)              90000             batch_normalization_1[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)                     (None, 40, 40, 100)              0                 conv2d_1[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","dropout (Dropout)                                (None, 40, 40, 100)              0                 max_pooling2d[0][0]                               \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_2 (Conv2D)                                (None, 40, 40, 200)              180000            dropout[0][0]                                     \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_2 (BatchNormalization)       (None, 40, 40, 200)              800               conv2d_2[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_3 (Conv2D)                                (None, 40, 40, 200)              360000            batch_normalization_2[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)                   (None, 20, 20, 200)              0                 conv2d_3[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","dropout_1 (Dropout)                              (None, 20, 20, 200)              0                 max_pooling2d_1[0][0]                             \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_4 (Conv2D)                                (None, 20, 20, 400)              720000            dropout_1[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_3 (BatchNormalization)       (None, 20, 20, 400)              1600              conv2d_4[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_5 (Conv2D)                                (None, 20, 20, 400)              1440000           batch_normalization_3[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)                   (None, 10, 10, 400)              0                 conv2d_5[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","dropout_2 (Dropout)                              (None, 10, 10, 400)              0                 max_pooling2d_2[0][0]                             \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_6 (Conv2D)                                (None, 10, 10, 800)              2880000           dropout_2[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_4 (BatchNormalization)       (None, 10, 10, 800)              3200              conv2d_6[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_7 (Conv2D)                                (None, 10, 10, 800)              5760000           batch_normalization_4[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)                   (None, 5, 5, 800)                0                 conv2d_7[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","dropout_3 (Dropout)                              (None, 5, 5, 800)                0                 max_pooling2d_3[0][0]                             \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_8 (Conv2D)                                (None, 5, 5, 1600)               11520000          dropout_3[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_5 (BatchNormalization)       (None, 5, 5, 1600)               6400              conv2d_8[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_9 (Conv2D)                                (None, 5, 5, 1600)               23040000          batch_normalization_5[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspose)               (None, 10, 10, 800)              11520000          conv2d_9[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","concatenate (Concatenate)                        (None, 10, 10, 1600)             0                 conv2d_transpose[0][0]                            \n","                                                                                                    conv2d_7[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_10 (Conv2D)                               (None, 10, 10, 800)              11520000          concatenate[0][0]                                 \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_6 (BatchNormalization)       (None, 10, 10, 800)              3200              conv2d_10[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_11 (Conv2D)                               (None, 10, 10, 800)              5760000           batch_normalization_6[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","dropout_4 (Dropout)                              (None, 10, 10, 800)              0                 conv2d_11[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTranspose)             (None, 20, 20, 400)              2880000           dropout_4[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","concatenate_1 (Concatenate)                      (None, 20, 20, 800)              0                 conv2d_transpose_1[0][0]                          \n","                                                                                                    conv2d_5[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_12 (Conv2D)                               (None, 20, 20, 400)              2880000           concatenate_1[0][0]                               \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_7 (BatchNormalization)       (None, 20, 20, 400)              1600              conv2d_12[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_13 (Conv2D)                               (None, 20, 20, 400)              1440000           batch_normalization_7[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","dropout_5 (Dropout)                              (None, 20, 20, 400)              0                 conv2d_13[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTranspose)             (None, 40, 40, 200)              720000            dropout_5[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","concatenate_2 (Concatenate)                      (None, 40, 40, 400)              0                 conv2d_transpose_2[0][0]                          \n","                                                                                                    conv2d_3[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_14 (Conv2D)                               (None, 40, 40, 200)              720000            concatenate_2[0][0]                               \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_8 (BatchNormalization)       (None, 40, 40, 200)              800               conv2d_14[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_15 (Conv2D)                               (None, 40, 40, 200)              360000            batch_normalization_8[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","dropout_6 (Dropout)                              (None, 40, 40, 200)              0                 conv2d_15[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTranspose)             (None, 80, 80, 100)              180000            dropout_6[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","concatenate_3 (Concatenate)                      (None, 80, 80, 200)              0                 conv2d_transpose_3[0][0]                          \n","                                                                                                    conv2d_1[0][0]                                    \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_16 (Conv2D)                               (None, 80, 80, 100)              180000            concatenate_3[0][0]                               \n","______________________________________________________________________________________________________________________________________________________\n","batch_normalization_9 (BatchNormalization)       (None, 80, 80, 100)              400               conv2d_16[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_17 (Conv2D)                               (None, 80, 80, 100)              90000             batch_normalization_9[0][0]                       \n","______________________________________________________________________________________________________________________________________________________\n","dropout_7 (Dropout)                              (None, 80, 80, 100)              0                 conv2d_17[0][0]                                   \n","______________________________________________________________________________________________________________________________________________________\n","conv2d_18 (Conv2D)                               (None, 80, 80, 4)                400               dropout_7[0][0]                                   \n","======================================================================================================================================================\n","Total params: 84,259,704\n","Trainable params: 84,250,502\n","Non-trainable params: 9,202\n","______________________________________________________________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Z47vMc9ZJbR","executionInfo":{"status":"ok","timestamp":1609736373176,"user_tz":360,"elapsed":10365,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"a6ad0341-56cb-4636-a20e-e92a2366b2a2"},"source":["series_directory =pd.read_excel('02_training_2dunet_coronal_108uc_dir.xlsx')\r\n","\r\n","train_ids=series_directory[series_directory['Train_val_split'].str.contains(\"Train\")]['DIR_ID'].to_list()\r\n","val_ids=series_directory[series_directory['Train_val_split'].str.contains(\"Val\")]['DIR_ID'].to_list()\r\n","\r\n","print(len(train_ids), len(val_ids))\r\n","\r\n","training_scan_indexes = [train_id for train_id in train_ids if all( dim >= IMG_SIZE for dim in np.load(os.path.join(data_folder, 'SCAN_'+str(train_id)+'.npy')).shape)]\r\n","validation_scan_indexes = [val_id for val_id in val_ids if all( dim >= IMG_SIZE for dim in np.load(os.path.join(data_folder, 'SCAN_'+str(val_id)+'.npy')).shape)]\r\n","\r\n","'''\r\n","# For overfitting\r\n","training_scan_indexes = training_scan_indexes[0:4]\r\n","validation_scan_indexes = validation_scan_indexes[0:4]\r\n","'''\r\n","\r\n","print(len(training_scan_indexes),len(validation_scan_indexes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["71 37\n","58 28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bPNZsU-9eCB4"},"source":["'''\r\n","from tensorflow.keras.experimental import CosineDecayRestarts\r\n","lr_decayed_fn = (CosineDecayRestarts(initial_learning_rate = LR, first_decay_steps = 2500))\r\n","LR=lr_decayed_fn\r\n","'''\r\n","\r\n","#opt = Adam(learning_rate=LR)\r\n","#opt = Adam()\r\n","#opt = AdaBound(lr=LR, final_lr=0.1)\r\n","opt = SGD(learning_rate=LR, momentum=0.9, nesterov=True)\r\n","#opt = SGD(learning_rate=LR, momentum=0.9, nesterov=True)\r\n","\r\n","#opt = Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name=\"Adadelta\")\r\n","#opt = RMSprop(learning_rate=LR, rho=0.9, momentum=0.9, epsilon=1e-07, centered=True)\r\n","\r\n","\r\n","unet.compile(optimizer=opt, loss=training_loss, metrics=[dice_coef_loss])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhwKCrDEZNbv"},"source":["training_params = {'TRAINING_DATA_DIR':data_folder, \r\n","                   'scan_IDs':training_scan_indexes, \r\n","                   'num_scans_in_batch' : num_scans_in_batch, \r\n","                   'num_patches_in_batch':num_patches_in_batch, \r\n","                   'dim':patch_sz, \r\n","                   'view_plane':view_plane_2d,\r\n","                   'muscles':muscles,\r\n","                   'window_width':window_width,\r\n","                   'n_channels':1, \r\n","                   'n_classes':n_classes, \r\n","                   'shuffle':True,\r\n","                   'validation_flag':0}\r\n","\r\n","validation_params = {'TRAINING_DATA_DIR':data_folder, \r\n","                     'scan_IDs':validation_scan_indexes, \r\n","                     'num_scans_in_batch' : training_params['num_scans_in_batch']*2, \r\n","                     'num_patches_in_batch':num_patches_in_batch,\r\n","                     'dim':patch_sz, \r\n","                     'view_plane':view_plane_2d,\r\n","                     'muscles':muscles,\r\n","                     'window_width':window_width,\r\n","                     'n_channels':1, \r\n","                     'n_classes':n_classes, \r\n","                     'shuffle':True,\r\n","                     'validation_flag':1}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vwyM2_JeuHH"},"source":["# Generators\r\n","training_generator = DataGenerator(**training_params)\r\n","validation_generator = DataGenerator(**validation_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-O3ww8xJiB8-","executionInfo":{"status":"ok","timestamp":1609736373193,"user_tz":360,"elapsed":10357,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"810b9cf0-b8f5-4048-a166-f7a8b6074e6b"},"source":["# The iteration with specified hyperparameters will be saved using this suffix\r\n","iteration_suffix=str(str(model_architecture)+\r\n","                     \"_\"+str(IMG_SIZE)+\"sz\"+ \r\n","                     \"_\"+str(unet_depth)+\"dp\"+ \r\n","                     \"_\"+str(len(patch_sz))+\"d\"+\r\n","                     \"_\"+str(view_plane_2d)+\"vp\"+\r\n","                     \"_\"+str(num_scans_in_batch)+\"sb\"+\r\n","                     \"_\"+str(num_patches_in_batch)+\"pb\"+\r\n","                     \"_\"+str(num_epochs)+\"ep\"+\r\n","                     \"_\"+str(n_filters_start)+\"sf\"+\r\n","                     \"_\"+str(LR)+\"lr\"+\r\n","                     \"_\"+str(window_width)+\"ww\"+\r\n","                     \"_\"+str(loss_function)+\"ls\"\r\n","                     )\r\n","\r\n","\r\n","\r\n","results_dir=os.path.join('./', iteration_suffix)\r\n","log_dir = str(results_dir)+'/'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n","\r\n","if not os.path.exists(results_dir): os.mkdir(results_dir)\r\n","if not os.path.exists(log_dir): os.mkdir(log_dir)\r\n","\r\n","print(\"Iteration suffix is: \"+str(iteration_suffix))\r\n","print(\"Results directory: \"+str(results_dir))\r\n","print(\"Log directory for Tensorboard: \"+str(log_dir))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Iteration suffix is: unet_2d_unet_80sz_nadp_2d_2dvp_4sb_100pb_500ep_nasf_0.005lr_400ww_dice_wbce_lossls\n","Results directory: ./unet_2d_unet_80sz_nadp_2d_2dvp_4sb_100pb_500ep_nasf_0.005lr_400ww_dice_wbce_lossls\n","Log directory for Tensorboard: ./unet_2d_unet_80sz_nadp_2d_2dvp_4sb_100pb_500ep_nasf_0.005lr_400ww_dice_wbce_lossls/20210104-045933\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7wr3cePslnTG"},"source":["# Continue training for specific number of epochs\r\n","csv_logger = CSVLogger(os.path.join(log_dir, \"01_training_history\"+str(iteration_suffix)+\".csv\"), append=True)\r\n","weight_saver = ModelCheckpoint(os.path.join(log_dir, '02_unet'+str(iteration_suffix)+'.h5'), \r\n","                               monitor='val_dice_coef_loss', \r\n","                               save_best_only=True)\r\n","\r\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n","es = EarlyStopping(monitor='val_dice_coef_loss', mode='min', verbose=1, patience=50)\r\n","\r\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_zP3_Z7l1L5","colab":{"base_uri":"https://localhost:8080/","height":873},"executionInfo":{"status":"ok","timestamp":1609736373198,"user_tz":360,"elapsed":10348,"user":{"displayName":"Ramkumar Shanker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkoluPwMR_8q7cdGzbZGXJ9SlwmfjMa_454ua8NA=s64","userId":"15106650102188691413"}},"outputId":"1a691bcc-7523-4143-e7ee-3e5609f75bc8"},"source":["# Load the TensorBoard notebook extension\r\n","%load_ext tensorboard\r\n","%tensorboard --logdir './'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 302), started 14:04:37 ago. (Use '!kill 302' to kill it.)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","        (async () => {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"f8FzErNvlyBi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2994727-e3fd-4e49-e724-c6d0f317c395"},"source":["# TRAIN\r\n","\r\n","history =  unet.fit(x=training_generator, \r\n","                    validation_data=validation_generator, \r\n","                    epochs=num_epochs, \r\n","                    verbose=1\r\n","                    , callbacks=[weight_saver, tensorboard_callback, reduce_lr \r\n","                                 ] \r\n","                    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","55/55 [==============================] - 123s 2s/step - loss: 1.0786 - dice_coef_loss: 0.9882 - val_loss: 1.0580 - val_dice_coef_loss: 0.9856\n","Epoch 2/500\n","55/55 [==============================] - 133s 2s/step - loss: 1.0332 - dice_coef_loss: 0.9839 - val_loss: 1.0525 - val_dice_coef_loss: 0.9852\n","Epoch 3/500\n","55/55 [==============================] - 111s 2s/step - loss: 1.0109 - dice_coef_loss: 0.9806 - val_loss: 1.0414 - val_dice_coef_loss: 0.9847\n","Epoch 4/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.9972 - dice_coef_loss: 0.9745 - val_loss: 1.0269 - val_dice_coef_loss: 0.9828\n","Epoch 5/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.9821 - dice_coef_loss: 0.9641 - val_loss: 1.0094 - val_dice_coef_loss: 0.9797\n","Epoch 6/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.9621 - dice_coef_loss: 0.9447 - val_loss: 0.9990 - val_dice_coef_loss: 0.9769\n","Epoch 7/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.9261 - dice_coef_loss: 0.9098 - val_loss: 1.0055 - val_dice_coef_loss: 0.9789\n","Epoch 8/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.8635 - dice_coef_loss: 0.8424 - val_loss: 1.0286 - val_dice_coef_loss: 0.9907\n","Epoch 9/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.8192 - dice_coef_loss: 0.7933 - val_loss: 1.0370 - val_dice_coef_loss: 0.9935\n","Epoch 10/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.7769 - dice_coef_loss: 0.7491 - val_loss: 1.0063 - val_dice_coef_loss: 0.9653\n","Epoch 11/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.7603 - dice_coef_loss: 0.7326 - val_loss: 0.8200 - val_dice_coef_loss: 0.7850\n","Epoch 12/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.7501 - dice_coef_loss: 0.7213 - val_loss: 0.7029 - val_dice_coef_loss: 0.6734\n","Epoch 13/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.7292 - dice_coef_loss: 0.7028 - val_loss: 0.6900 - val_dice_coef_loss: 0.6612\n","Epoch 14/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.7315 - dice_coef_loss: 0.7045 - val_loss: 0.6619 - val_dice_coef_loss: 0.6347\n","Epoch 15/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.7176 - dice_coef_loss: 0.6922 - val_loss: 0.6532 - val_dice_coef_loss: 0.6300\n","Epoch 16/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.7050 - dice_coef_loss: 0.6821 - val_loss: 0.6455 - val_dice_coef_loss: 0.6151\n","Epoch 17/500\n","55/55 [==============================] - 95s 2s/step - loss: 0.6711 - dice_coef_loss: 0.6499 - val_loss: 0.6519 - val_dice_coef_loss: 0.6172\n","Epoch 18/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.6359 - dice_coef_loss: 0.6151 - val_loss: 0.6449 - val_dice_coef_loss: 0.6111\n","Epoch 19/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.6166 - dice_coef_loss: 0.5942 - val_loss: 0.6243 - val_dice_coef_loss: 0.5919\n","Epoch 20/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.5988 - dice_coef_loss: 0.5767 - val_loss: 0.5820 - val_dice_coef_loss: 0.5529\n","Epoch 21/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.5772 - dice_coef_loss: 0.5567 - val_loss: 0.5548 - val_dice_coef_loss: 0.5296\n","Epoch 22/500\n","55/55 [==============================] - 117s 2s/step - loss: 0.5350 - dice_coef_loss: 0.5169 - val_loss: 0.4512 - val_dice_coef_loss: 0.4304\n","Epoch 23/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.4912 - dice_coef_loss: 0.4723 - val_loss: 0.4879 - val_dice_coef_loss: 0.4640\n","Epoch 24/500\n","55/55 [==============================] - 114s 2s/step - loss: 0.4685 - dice_coef_loss: 0.4504 - val_loss: 0.4033 - val_dice_coef_loss: 0.3844\n","Epoch 25/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.4566 - dice_coef_loss: 0.4384 - val_loss: 0.4216 - val_dice_coef_loss: 0.4032\n","Epoch 26/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.4398 - dice_coef_loss: 0.4214 - val_loss: 0.3897 - val_dice_coef_loss: 0.3713\n","Epoch 27/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.4287 - dice_coef_loss: 0.4105 - val_loss: 0.4437 - val_dice_coef_loss: 0.4259\n","Epoch 28/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.4341 - dice_coef_loss: 0.4168 - val_loss: 0.4062 - val_dice_coef_loss: 0.3885\n","Epoch 29/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.4180 - dice_coef_loss: 0.4008 - val_loss: 0.4319 - val_dice_coef_loss: 0.4132\n","Epoch 30/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.4105 - dice_coef_loss: 0.3949 - val_loss: 0.4008 - val_dice_coef_loss: 0.3817\n","Epoch 31/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.4050 - dice_coef_loss: 0.3893 - val_loss: 0.3813 - val_dice_coef_loss: 0.3644\n","Epoch 32/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.4035 - dice_coef_loss: 0.3874 - val_loss: 0.3986 - val_dice_coef_loss: 0.3807\n","Epoch 33/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.3990 - dice_coef_loss: 0.3842 - val_loss: 0.3763 - val_dice_coef_loss: 0.3630\n","Epoch 34/500\n","55/55 [==============================] - 113s 2s/step - loss: 0.3940 - dice_coef_loss: 0.3808 - val_loss: 0.3272 - val_dice_coef_loss: 0.3150\n","Epoch 35/500\n","55/55 [==============================] - 117s 2s/step - loss: 0.3547 - dice_coef_loss: 0.3428 - val_loss: 0.3082 - val_dice_coef_loss: 0.2968\n","Epoch 36/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.3471 - dice_coef_loss: 0.3352 - val_loss: 0.2918 - val_dice_coef_loss: 0.2800\n","Epoch 37/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.3327 - dice_coef_loss: 0.3212 - val_loss: 0.3027 - val_dice_coef_loss: 0.2910\n","Epoch 38/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.3159 - dice_coef_loss: 0.3047 - val_loss: 0.2941 - val_dice_coef_loss: 0.2838\n","Epoch 39/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.3180 - dice_coef_loss: 0.3072 - val_loss: 0.2903 - val_dice_coef_loss: 0.2795\n","Epoch 40/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.3099 - dice_coef_loss: 0.2981 - val_loss: 0.2828 - val_dice_coef_loss: 0.2693\n","Epoch 41/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.3087 - dice_coef_loss: 0.2976 - val_loss: 0.2833 - val_dice_coef_loss: 0.2719\n","Epoch 42/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.3028 - dice_coef_loss: 0.2921 - val_loss: 0.3051 - val_dice_coef_loss: 0.2909\n","Epoch 43/500\n","55/55 [==============================] - 116s 2s/step - loss: 0.3106 - dice_coef_loss: 0.3002 - val_loss: 0.3030 - val_dice_coef_loss: 0.2903\n","Epoch 44/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.3010 - dice_coef_loss: 0.2897 - val_loss: 0.3077 - val_dice_coef_loss: 0.2918\n","Epoch 45/500\n","55/55 [==============================] - 116s 2s/step - loss: 0.2926 - dice_coef_loss: 0.2825 - val_loss: 0.2979 - val_dice_coef_loss: 0.2829\n","Epoch 46/500\n","55/55 [==============================] - 119s 2s/step - loss: 0.2950 - dice_coef_loss: 0.2849 - val_loss: 0.2742 - val_dice_coef_loss: 0.2633\n","Epoch 47/500\n","55/55 [==============================] - 122s 2s/step - loss: 0.2835 - dice_coef_loss: 0.2723 - val_loss: 0.2838 - val_dice_coef_loss: 0.2733\n","Epoch 48/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2822 - dice_coef_loss: 0.2725 - val_loss: 0.2798 - val_dice_coef_loss: 0.2682\n","Epoch 49/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2826 - dice_coef_loss: 0.2722 - val_loss: 0.3323 - val_dice_coef_loss: 0.3109\n","Epoch 50/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2947 - dice_coef_loss: 0.2836 - val_loss: 0.2999 - val_dice_coef_loss: 0.2869\n","Epoch 51/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2877 - dice_coef_loss: 0.2763 - val_loss: 0.2784 - val_dice_coef_loss: 0.2660\n","Epoch 52/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2864 - dice_coef_loss: 0.2757 - val_loss: 0.2953 - val_dice_coef_loss: 0.2796\n","Epoch 53/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2698 - dice_coef_loss: 0.2604 - val_loss: 0.2856 - val_dice_coef_loss: 0.2708\n","Epoch 54/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.2793 - dice_coef_loss: 0.2692 - val_loss: 0.2803 - val_dice_coef_loss: 0.2686\n","Epoch 55/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2855 - dice_coef_loss: 0.2751 - val_loss: 0.3018 - val_dice_coef_loss: 0.2858\n","Epoch 56/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2801 - dice_coef_loss: 0.2697 - val_loss: 0.2669 - val_dice_coef_loss: 0.2556\n","Epoch 57/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2814 - dice_coef_loss: 0.2716 - val_loss: 0.2848 - val_dice_coef_loss: 0.2756\n","Epoch 58/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2685 - dice_coef_loss: 0.2585 - val_loss: 0.2792 - val_dice_coef_loss: 0.2686\n","Epoch 59/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2722 - dice_coef_loss: 0.2624 - val_loss: 0.2926 - val_dice_coef_loss: 0.2767\n","Epoch 60/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2672 - dice_coef_loss: 0.2573 - val_loss: 0.2768 - val_dice_coef_loss: 0.2613\n","Epoch 61/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2736 - dice_coef_loss: 0.2637 - val_loss: 0.3186 - val_dice_coef_loss: 0.2975\n","Epoch 62/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2679 - dice_coef_loss: 0.2578 - val_loss: 0.2752 - val_dice_coef_loss: 0.2620\n","Epoch 63/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2746 - dice_coef_loss: 0.2653 - val_loss: 0.3171 - val_dice_coef_loss: 0.2965\n","Epoch 64/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2580 - dice_coef_loss: 0.2484 - val_loss: 0.2842 - val_dice_coef_loss: 0.2680\n","Epoch 65/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2631 - dice_coef_loss: 0.2533 - val_loss: 0.3673 - val_dice_coef_loss: 0.3401\n","Epoch 66/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2570 - dice_coef_loss: 0.2474 - val_loss: 0.2815 - val_dice_coef_loss: 0.2683\n","Epoch 67/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2587 - dice_coef_loss: 0.2486 - val_loss: 0.2947 - val_dice_coef_loss: 0.2786\n","Epoch 68/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2564 - dice_coef_loss: 0.2472 - val_loss: 0.2758 - val_dice_coef_loss: 0.2624\n","Epoch 69/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2550 - dice_coef_loss: 0.2461 - val_loss: 0.2683 - val_dice_coef_loss: 0.2555\n","Epoch 70/500\n","55/55 [==============================] - 111s 2s/step - loss: 0.2611 - dice_coef_loss: 0.2518 - val_loss: 0.2664 - val_dice_coef_loss: 0.2536\n","Epoch 71/500\n","55/55 [==============================] - 113s 2s/step - loss: 0.2559 - dice_coef_loss: 0.2464 - val_loss: 0.2734 - val_dice_coef_loss: 0.2608\n","Epoch 72/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2468 - dice_coef_loss: 0.2374 - val_loss: 0.2633 - val_dice_coef_loss: 0.2514\n","Epoch 73/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2613 - dice_coef_loss: 0.2523 - val_loss: 0.2662 - val_dice_coef_loss: 0.2542\n","Epoch 74/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2445 - dice_coef_loss: 0.2353 - val_loss: 0.2510 - val_dice_coef_loss: 0.2410\n","Epoch 75/500\n","55/55 [==============================] - 96s 2s/step - loss: 0.2479 - dice_coef_loss: 0.2381 - val_loss: 0.2755 - val_dice_coef_loss: 0.2616\n","Epoch 76/500\n","55/55 [==============================] - 96s 2s/step - loss: 0.2507 - dice_coef_loss: 0.2418 - val_loss: 0.2665 - val_dice_coef_loss: 0.2536\n","Epoch 77/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2526 - dice_coef_loss: 0.2436 - val_loss: 0.2488 - val_dice_coef_loss: 0.2386\n","Epoch 78/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2576 - dice_coef_loss: 0.2486 - val_loss: 0.2522 - val_dice_coef_loss: 0.2421\n","Epoch 79/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2484 - dice_coef_loss: 0.2394 - val_loss: 0.2745 - val_dice_coef_loss: 0.2605\n","Epoch 80/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2378 - dice_coef_loss: 0.2290 - val_loss: 0.2661 - val_dice_coef_loss: 0.2533\n","Epoch 81/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2544 - dice_coef_loss: 0.2454 - val_loss: 0.2742 - val_dice_coef_loss: 0.2599\n","Epoch 82/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2499 - dice_coef_loss: 0.2413 - val_loss: 0.2807 - val_dice_coef_loss: 0.2661\n","Epoch 83/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2614 - dice_coef_loss: 0.2518 - val_loss: 0.2621 - val_dice_coef_loss: 0.2501\n","Epoch 84/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2486 - dice_coef_loss: 0.2398 - val_loss: 0.2727 - val_dice_coef_loss: 0.2610\n","Epoch 85/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2456 - dice_coef_loss: 0.2373 - val_loss: 0.2684 - val_dice_coef_loss: 0.2554\n","Epoch 86/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2509 - dice_coef_loss: 0.2418 - val_loss: 0.2576 - val_dice_coef_loss: 0.2479\n","Epoch 87/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2589 - dice_coef_loss: 0.2499 - val_loss: 0.2605 - val_dice_coef_loss: 0.2484\n","Epoch 88/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2685 - dice_coef_loss: 0.2591 - val_loss: 0.2765 - val_dice_coef_loss: 0.2632\n","Epoch 89/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2508 - dice_coef_loss: 0.2417 - val_loss: 0.2823 - val_dice_coef_loss: 0.2686\n","Epoch 90/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2569 - dice_coef_loss: 0.2481 - val_loss: 0.2747 - val_dice_coef_loss: 0.2612\n","Epoch 91/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2626 - dice_coef_loss: 0.2538 - val_loss: 0.2677 - val_dice_coef_loss: 0.2551\n","Epoch 92/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2466 - dice_coef_loss: 0.2378 - val_loss: 0.2584 - val_dice_coef_loss: 0.2472\n","Epoch 93/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2482 - dice_coef_loss: 0.2388 - val_loss: 0.2610 - val_dice_coef_loss: 0.2502\n","Epoch 94/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2513 - dice_coef_loss: 0.2422 - val_loss: 0.2661 - val_dice_coef_loss: 0.2535\n","Epoch 95/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2543 - dice_coef_loss: 0.2450 - val_loss: 0.2609 - val_dice_coef_loss: 0.2488\n","Epoch 96/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2499 - dice_coef_loss: 0.2411 - val_loss: 0.2750 - val_dice_coef_loss: 0.2613\n","Epoch 97/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2435 - dice_coef_loss: 0.2354 - val_loss: 0.2686 - val_dice_coef_loss: 0.2557\n","Epoch 98/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2643 - dice_coef_loss: 0.2552 - val_loss: 0.2507 - val_dice_coef_loss: 0.2402\n","Epoch 99/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2501 - dice_coef_loss: 0.2407 - val_loss: 0.2543 - val_dice_coef_loss: 0.2437\n","Epoch 100/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2479 - dice_coef_loss: 0.2389 - val_loss: 0.2559 - val_dice_coef_loss: 0.2453\n","Epoch 101/500\n","55/55 [==============================] - 94s 2s/step - loss: 0.2607 - dice_coef_loss: 0.2518 - val_loss: 0.2634 - val_dice_coef_loss: 0.2505\n","Epoch 102/500\n","55/55 [==============================] - 91s 2s/step - loss: 0.2470 - dice_coef_loss: 0.2381 - val_loss: 0.2614 - val_dice_coef_loss: 0.2495\n","Epoch 103/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2596 - dice_coef_loss: 0.2510 - val_loss: 0.2578 - val_dice_coef_loss: 0.2463\n","Epoch 104/500\n","55/55 [==============================] - 96s 2s/step - loss: 0.2572 - dice_coef_loss: 0.2477 - val_loss: 0.2557 - val_dice_coef_loss: 0.2444\n","Epoch 105/500\n","55/55 [==============================] - 94s 2s/step - loss: 0.2503 - dice_coef_loss: 0.2414 - val_loss: 0.2605 - val_dice_coef_loss: 0.2490\n","Epoch 106/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2456 - dice_coef_loss: 0.2372 - val_loss: 0.2546 - val_dice_coef_loss: 0.2438\n","Epoch 107/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2456 - dice_coef_loss: 0.2375 - val_loss: 0.2596 - val_dice_coef_loss: 0.2483\n","Epoch 108/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2464 - dice_coef_loss: 0.2369 - val_loss: 0.2731 - val_dice_coef_loss: 0.2587\n","Epoch 109/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2566 - dice_coef_loss: 0.2473 - val_loss: 0.2647 - val_dice_coef_loss: 0.2525\n","Epoch 110/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2494 - dice_coef_loss: 0.2405 - val_loss: 0.2632 - val_dice_coef_loss: 0.2506\n","Epoch 111/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2556 - dice_coef_loss: 0.2465 - val_loss: 0.2498 - val_dice_coef_loss: 0.2397\n","Epoch 112/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2416 - dice_coef_loss: 0.2328 - val_loss: 0.2636 - val_dice_coef_loss: 0.2511\n","Epoch 113/500\n","55/55 [==============================] - 113s 2s/step - loss: 0.2500 - dice_coef_loss: 0.2403 - val_loss: 0.2646 - val_dice_coef_loss: 0.2532\n","Epoch 114/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2530 - dice_coef_loss: 0.2441 - val_loss: 0.2638 - val_dice_coef_loss: 0.2518\n","Epoch 115/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.2649 - dice_coef_loss: 0.2562 - val_loss: 0.2633 - val_dice_coef_loss: 0.2514\n","Epoch 116/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2576 - dice_coef_loss: 0.2488 - val_loss: 0.2751 - val_dice_coef_loss: 0.2609\n","Epoch 117/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2587 - dice_coef_loss: 0.2492 - val_loss: 0.2608 - val_dice_coef_loss: 0.2489\n","Epoch 118/500\n","55/55 [==============================] - 125s 2s/step - loss: 0.2612 - dice_coef_loss: 0.2523 - val_loss: 0.2522 - val_dice_coef_loss: 0.2418\n","Epoch 119/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2513 - dice_coef_loss: 0.2429 - val_loss: 0.2702 - val_dice_coef_loss: 0.2565\n","Epoch 120/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2472 - dice_coef_loss: 0.2381 - val_loss: 0.2630 - val_dice_coef_loss: 0.2502\n","Epoch 121/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2624 - dice_coef_loss: 0.2524 - val_loss: 0.2709 - val_dice_coef_loss: 0.2576\n","Epoch 122/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2557 - dice_coef_loss: 0.2468 - val_loss: 0.2571 - val_dice_coef_loss: 0.2454\n","Epoch 123/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2655 - dice_coef_loss: 0.2558 - val_loss: 0.2553 - val_dice_coef_loss: 0.2447\n","Epoch 124/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2445 - dice_coef_loss: 0.2350 - val_loss: 0.2716 - val_dice_coef_loss: 0.2582\n","Epoch 125/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2490 - dice_coef_loss: 0.2401 - val_loss: 0.2704 - val_dice_coef_loss: 0.2566\n","Epoch 126/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2468 - dice_coef_loss: 0.2386 - val_loss: 0.2532 - val_dice_coef_loss: 0.2424\n","Epoch 127/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2552 - dice_coef_loss: 0.2450 - val_loss: 0.2598 - val_dice_coef_loss: 0.2481\n","Epoch 128/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2579 - dice_coef_loss: 0.2479 - val_loss: 0.2725 - val_dice_coef_loss: 0.2598\n","Epoch 129/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2428 - dice_coef_loss: 0.2336 - val_loss: 0.2658 - val_dice_coef_loss: 0.2529\n","Epoch 130/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2505 - dice_coef_loss: 0.2414 - val_loss: 0.2787 - val_dice_coef_loss: 0.2650\n","Epoch 131/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2528 - dice_coef_loss: 0.2437 - val_loss: 0.2552 - val_dice_coef_loss: 0.2444\n","Epoch 132/500\n","55/55 [==============================] - 96s 2s/step - loss: 0.2580 - dice_coef_loss: 0.2493 - val_loss: 0.2617 - val_dice_coef_loss: 0.2495\n","Epoch 133/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2494 - dice_coef_loss: 0.2404 - val_loss: 0.2691 - val_dice_coef_loss: 0.2560\n","Epoch 134/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2433 - dice_coef_loss: 0.2348 - val_loss: 0.2645 - val_dice_coef_loss: 0.2523\n","Epoch 135/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2534 - dice_coef_loss: 0.2441 - val_loss: 0.2384 - val_dice_coef_loss: 0.2296\n","Epoch 136/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2438 - dice_coef_loss: 0.2351 - val_loss: 0.2724 - val_dice_coef_loss: 0.2582\n","Epoch 137/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2563 - dice_coef_loss: 0.2476 - val_loss: 0.2653 - val_dice_coef_loss: 0.2531\n","Epoch 138/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2513 - dice_coef_loss: 0.2425 - val_loss: 0.2517 - val_dice_coef_loss: 0.2410\n","Epoch 139/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2559 - dice_coef_loss: 0.2469 - val_loss: 0.2656 - val_dice_coef_loss: 0.2535\n","Epoch 140/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2436 - dice_coef_loss: 0.2357 - val_loss: 0.2666 - val_dice_coef_loss: 0.2543\n","Epoch 141/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2471 - dice_coef_loss: 0.2388 - val_loss: 0.2698 - val_dice_coef_loss: 0.2560\n","Epoch 142/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2478 - dice_coef_loss: 0.2392 - val_loss: 0.2561 - val_dice_coef_loss: 0.2449\n","Epoch 143/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2612 - dice_coef_loss: 0.2520 - val_loss: 0.2726 - val_dice_coef_loss: 0.2588\n","Epoch 144/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2477 - dice_coef_loss: 0.2383 - val_loss: 0.2721 - val_dice_coef_loss: 0.2584\n","Epoch 145/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.2632 - dice_coef_loss: 0.2538 - val_loss: 0.2640 - val_dice_coef_loss: 0.2515\n","Epoch 146/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2446 - dice_coef_loss: 0.2361 - val_loss: 0.2531 - val_dice_coef_loss: 0.2431\n","Epoch 147/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.2430 - dice_coef_loss: 0.2342 - val_loss: 0.2690 - val_dice_coef_loss: 0.2566\n","Epoch 148/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2479 - dice_coef_loss: 0.2389 - val_loss: 0.2732 - val_dice_coef_loss: 0.2600\n","Epoch 149/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2487 - dice_coef_loss: 0.2394 - val_loss: 0.2622 - val_dice_coef_loss: 0.2495\n","Epoch 150/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2470 - dice_coef_loss: 0.2379 - val_loss: 0.2591 - val_dice_coef_loss: 0.2480\n","Epoch 151/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2537 - dice_coef_loss: 0.2445 - val_loss: 0.2678 - val_dice_coef_loss: 0.2552\n","Epoch 152/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2456 - dice_coef_loss: 0.2370 - val_loss: 0.2598 - val_dice_coef_loss: 0.2472\n","Epoch 153/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2505 - dice_coef_loss: 0.2413 - val_loss: 0.2685 - val_dice_coef_loss: 0.2551\n","Epoch 154/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2580 - dice_coef_loss: 0.2486 - val_loss: 0.2490 - val_dice_coef_loss: 0.2384\n","Epoch 155/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2620 - dice_coef_loss: 0.2532 - val_loss: 0.2454 - val_dice_coef_loss: 0.2354\n","Epoch 156/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2548 - dice_coef_loss: 0.2460 - val_loss: 0.2515 - val_dice_coef_loss: 0.2409\n","Epoch 157/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2571 - dice_coef_loss: 0.2475 - val_loss: 0.2723 - val_dice_coef_loss: 0.2588\n","Epoch 158/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2438 - dice_coef_loss: 0.2351 - val_loss: 0.2609 - val_dice_coef_loss: 0.2497\n","Epoch 159/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2462 - dice_coef_loss: 0.2365 - val_loss: 0.2686 - val_dice_coef_loss: 0.2548\n","Epoch 160/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.2586 - dice_coef_loss: 0.2495 - val_loss: 0.2828 - val_dice_coef_loss: 0.2683\n","Epoch 161/500\n","55/55 [==============================] - 113s 2s/step - loss: 0.2453 - dice_coef_loss: 0.2365 - val_loss: 0.2756 - val_dice_coef_loss: 0.2616\n","Epoch 162/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2636 - dice_coef_loss: 0.2545 - val_loss: 0.2734 - val_dice_coef_loss: 0.2595\n","Epoch 163/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2486 - dice_coef_loss: 0.2397 - val_loss: 0.2638 - val_dice_coef_loss: 0.2517\n","Epoch 164/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2477 - dice_coef_loss: 0.2386 - val_loss: 0.2749 - val_dice_coef_loss: 0.2612\n","Epoch 165/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2426 - dice_coef_loss: 0.2338 - val_loss: 0.2716 - val_dice_coef_loss: 0.2580\n","Epoch 166/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2526 - dice_coef_loss: 0.2436 - val_loss: 0.2749 - val_dice_coef_loss: 0.2621\n","Epoch 167/500\n","55/55 [==============================] - 111s 2s/step - loss: 0.2555 - dice_coef_loss: 0.2464 - val_loss: 0.2609 - val_dice_coef_loss: 0.2496\n","Epoch 168/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2525 - dice_coef_loss: 0.2442 - val_loss: 0.2615 - val_dice_coef_loss: 0.2500\n","Epoch 169/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2491 - dice_coef_loss: 0.2401 - val_loss: 0.2653 - val_dice_coef_loss: 0.2527\n","Epoch 170/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2517 - dice_coef_loss: 0.2432 - val_loss: 0.2791 - val_dice_coef_loss: 0.2654\n","Epoch 171/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2559 - dice_coef_loss: 0.2469 - val_loss: 0.2643 - val_dice_coef_loss: 0.2520\n","Epoch 172/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2614 - dice_coef_loss: 0.2516 - val_loss: 0.2559 - val_dice_coef_loss: 0.2443\n","Epoch 173/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2434 - dice_coef_loss: 0.2341 - val_loss: 0.2638 - val_dice_coef_loss: 0.2521\n","Epoch 174/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2606 - dice_coef_loss: 0.2516 - val_loss: 0.2640 - val_dice_coef_loss: 0.2515\n","Epoch 175/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2484 - dice_coef_loss: 0.2394 - val_loss: 0.2834 - val_dice_coef_loss: 0.2689\n","Epoch 176/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2520 - dice_coef_loss: 0.2428 - val_loss: 0.2629 - val_dice_coef_loss: 0.2513\n","Epoch 177/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2582 - dice_coef_loss: 0.2487 - val_loss: 0.2724 - val_dice_coef_loss: 0.2584\n","Epoch 178/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2430 - dice_coef_loss: 0.2341 - val_loss: 0.2517 - val_dice_coef_loss: 0.2413\n","Epoch 179/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2457 - dice_coef_loss: 0.2365 - val_loss: 0.2702 - val_dice_coef_loss: 0.2569\n","Epoch 180/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.2495 - dice_coef_loss: 0.2402 - val_loss: 0.2777 - val_dice_coef_loss: 0.2634\n","Epoch 181/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2382 - dice_coef_loss: 0.2296 - val_loss: 0.2674 - val_dice_coef_loss: 0.2546\n","Epoch 182/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2573 - dice_coef_loss: 0.2489 - val_loss: 0.2621 - val_dice_coef_loss: 0.2509\n","Epoch 183/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2519 - dice_coef_loss: 0.2428 - val_loss: 0.2580 - val_dice_coef_loss: 0.2460\n","Epoch 184/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2561 - dice_coef_loss: 0.2474 - val_loss: 0.2660 - val_dice_coef_loss: 0.2529\n","Epoch 185/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2609 - dice_coef_loss: 0.2520 - val_loss: 0.2880 - val_dice_coef_loss: 0.2733\n","Epoch 186/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2575 - dice_coef_loss: 0.2481 - val_loss: 0.2620 - val_dice_coef_loss: 0.2499\n","Epoch 187/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2493 - dice_coef_loss: 0.2400 - val_loss: 0.2677 - val_dice_coef_loss: 0.2543\n","Epoch 188/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2481 - dice_coef_loss: 0.2394 - val_loss: 0.2686 - val_dice_coef_loss: 0.2552\n","Epoch 189/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2543 - dice_coef_loss: 0.2452 - val_loss: 0.2646 - val_dice_coef_loss: 0.2515\n","Epoch 190/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2618 - dice_coef_loss: 0.2523 - val_loss: 0.2685 - val_dice_coef_loss: 0.2555\n","Epoch 191/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2574 - dice_coef_loss: 0.2483 - val_loss: 0.2586 - val_dice_coef_loss: 0.2470\n","Epoch 192/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2567 - dice_coef_loss: 0.2475 - val_loss: 0.2648 - val_dice_coef_loss: 0.2524\n","Epoch 193/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2571 - dice_coef_loss: 0.2474 - val_loss: 0.2600 - val_dice_coef_loss: 0.2486\n","Epoch 194/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2540 - dice_coef_loss: 0.2451 - val_loss: 0.2607 - val_dice_coef_loss: 0.2486\n","Epoch 195/500\n","55/55 [==============================] - 111s 2s/step - loss: 0.2653 - dice_coef_loss: 0.2562 - val_loss: 0.2654 - val_dice_coef_loss: 0.2523\n","Epoch 196/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2475 - dice_coef_loss: 0.2389 - val_loss: 0.2712 - val_dice_coef_loss: 0.2583\n","Epoch 197/500\n","55/55 [==============================] - 112s 2s/step - loss: 0.2497 - dice_coef_loss: 0.2407 - val_loss: 0.2750 - val_dice_coef_loss: 0.2612\n","Epoch 198/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2513 - dice_coef_loss: 0.2427 - val_loss: 0.2600 - val_dice_coef_loss: 0.2479\n","Epoch 199/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2374 - dice_coef_loss: 0.2289 - val_loss: 0.2529 - val_dice_coef_loss: 0.2425\n","Epoch 200/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2445 - dice_coef_loss: 0.2353 - val_loss: 0.2718 - val_dice_coef_loss: 0.2582\n","Epoch 201/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2434 - dice_coef_loss: 0.2345 - val_loss: 0.2768 - val_dice_coef_loss: 0.2618\n","Epoch 202/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2576 - dice_coef_loss: 0.2490 - val_loss: 0.2563 - val_dice_coef_loss: 0.2454\n","Epoch 203/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2541 - dice_coef_loss: 0.2449 - val_loss: 0.2494 - val_dice_coef_loss: 0.2388\n","Epoch 204/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2499 - dice_coef_loss: 0.2411 - val_loss: 0.2589 - val_dice_coef_loss: 0.2470\n","Epoch 205/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2504 - dice_coef_loss: 0.2415 - val_loss: 0.2661 - val_dice_coef_loss: 0.2538\n","Epoch 206/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2428 - dice_coef_loss: 0.2341 - val_loss: 0.2580 - val_dice_coef_loss: 0.2476\n","Epoch 207/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2559 - dice_coef_loss: 0.2470 - val_loss: 0.2795 - val_dice_coef_loss: 0.2649\n","Epoch 208/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2464 - dice_coef_loss: 0.2370 - val_loss: 0.2521 - val_dice_coef_loss: 0.2413\n","Epoch 209/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2464 - dice_coef_loss: 0.2375 - val_loss: 0.2651 - val_dice_coef_loss: 0.2523\n","Epoch 210/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2478 - dice_coef_loss: 0.2383 - val_loss: 0.2568 - val_dice_coef_loss: 0.2462\n","Epoch 211/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2591 - dice_coef_loss: 0.2497 - val_loss: 0.2770 - val_dice_coef_loss: 0.2636\n","Epoch 212/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2523 - dice_coef_loss: 0.2429 - val_loss: 0.2811 - val_dice_coef_loss: 0.2665\n","Epoch 213/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2515 - dice_coef_loss: 0.2423 - val_loss: 0.2753 - val_dice_coef_loss: 0.2615\n","Epoch 214/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2520 - dice_coef_loss: 0.2431 - val_loss: 0.2735 - val_dice_coef_loss: 0.2591\n","Epoch 215/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2522 - dice_coef_loss: 0.2431 - val_loss: 0.2561 - val_dice_coef_loss: 0.2448\n","Epoch 216/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2626 - dice_coef_loss: 0.2530 - val_loss: 0.2828 - val_dice_coef_loss: 0.2681\n","Epoch 217/500\n","55/55 [==============================] - 97s 2s/step - loss: 0.2498 - dice_coef_loss: 0.2411 - val_loss: 0.2604 - val_dice_coef_loss: 0.2481\n","Epoch 218/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2503 - dice_coef_loss: 0.2421 - val_loss: 0.2613 - val_dice_coef_loss: 0.2486\n","Epoch 219/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2495 - dice_coef_loss: 0.2409 - val_loss: 0.2798 - val_dice_coef_loss: 0.2658\n","Epoch 220/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2515 - dice_coef_loss: 0.2417 - val_loss: 0.2655 - val_dice_coef_loss: 0.2525\n","Epoch 221/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2473 - dice_coef_loss: 0.2383 - val_loss: 0.2643 - val_dice_coef_loss: 0.2516\n","Epoch 222/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2488 - dice_coef_loss: 0.2400 - val_loss: 0.2614 - val_dice_coef_loss: 0.2499\n","Epoch 223/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2607 - dice_coef_loss: 0.2516 - val_loss: 0.2623 - val_dice_coef_loss: 0.2505\n","Epoch 224/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2631 - dice_coef_loss: 0.2537 - val_loss: 0.2533 - val_dice_coef_loss: 0.2436\n","Epoch 225/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2539 - dice_coef_loss: 0.2446 - val_loss: 0.2717 - val_dice_coef_loss: 0.2583\n","Epoch 226/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2523 - dice_coef_loss: 0.2432 - val_loss: 0.2633 - val_dice_coef_loss: 0.2513\n","Epoch 227/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2514 - dice_coef_loss: 0.2425 - val_loss: 0.2804 - val_dice_coef_loss: 0.2658\n","Epoch 228/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2532 - dice_coef_loss: 0.2443 - val_loss: 0.2503 - val_dice_coef_loss: 0.2400\n","Epoch 229/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.2495 - dice_coef_loss: 0.2401 - val_loss: 0.2686 - val_dice_coef_loss: 0.2571\n","Epoch 230/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2470 - dice_coef_loss: 0.2384 - val_loss: 0.2631 - val_dice_coef_loss: 0.2512\n","Epoch 231/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2458 - dice_coef_loss: 0.2369 - val_loss: 0.2696 - val_dice_coef_loss: 0.2570\n","Epoch 232/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2436 - dice_coef_loss: 0.2349 - val_loss: 0.2724 - val_dice_coef_loss: 0.2594\n","Epoch 233/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2545 - dice_coef_loss: 0.2453 - val_loss: 0.2672 - val_dice_coef_loss: 0.2539\n","Epoch 234/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2545 - dice_coef_loss: 0.2455 - val_loss: 0.2627 - val_dice_coef_loss: 0.2506\n","Epoch 235/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2451 - dice_coef_loss: 0.2360 - val_loss: 0.2705 - val_dice_coef_loss: 0.2576\n","Epoch 236/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2461 - dice_coef_loss: 0.2372 - val_loss: 0.2579 - val_dice_coef_loss: 0.2466\n","Epoch 237/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2576 - dice_coef_loss: 0.2488 - val_loss: 0.2535 - val_dice_coef_loss: 0.2430\n","Epoch 238/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2505 - dice_coef_loss: 0.2412 - val_loss: 0.2514 - val_dice_coef_loss: 0.2402\n","Epoch 239/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2488 - dice_coef_loss: 0.2405 - val_loss: 0.2688 - val_dice_coef_loss: 0.2561\n","Epoch 240/500\n","55/55 [==============================] - 96s 2s/step - loss: 0.2457 - dice_coef_loss: 0.2371 - val_loss: 0.2789 - val_dice_coef_loss: 0.2647\n","Epoch 241/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2598 - dice_coef_loss: 0.2508 - val_loss: 0.2628 - val_dice_coef_loss: 0.2505\n","Epoch 242/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2577 - dice_coef_loss: 0.2490 - val_loss: 0.2811 - val_dice_coef_loss: 0.2667\n","Epoch 243/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2504 - dice_coef_loss: 0.2419 - val_loss: 0.2730 - val_dice_coef_loss: 0.2597\n","Epoch 244/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2553 - dice_coef_loss: 0.2467 - val_loss: 0.2581 - val_dice_coef_loss: 0.2470\n","Epoch 245/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2450 - dice_coef_loss: 0.2361 - val_loss: 0.2633 - val_dice_coef_loss: 0.2515\n","Epoch 246/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2476 - dice_coef_loss: 0.2386 - val_loss: 0.2721 - val_dice_coef_loss: 0.2591\n","Epoch 247/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2455 - dice_coef_loss: 0.2368 - val_loss: 0.2681 - val_dice_coef_loss: 0.2554\n","Epoch 248/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2562 - dice_coef_loss: 0.2473 - val_loss: 0.2661 - val_dice_coef_loss: 0.2534\n","Epoch 249/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2581 - dice_coef_loss: 0.2481 - val_loss: 0.2521 - val_dice_coef_loss: 0.2418\n","Epoch 250/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2559 - dice_coef_loss: 0.2462 - val_loss: 0.2658 - val_dice_coef_loss: 0.2536\n","Epoch 251/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2624 - dice_coef_loss: 0.2540 - val_loss: 0.2767 - val_dice_coef_loss: 0.2633\n","Epoch 252/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2452 - dice_coef_loss: 0.2359 - val_loss: 0.2641 - val_dice_coef_loss: 0.2519\n","Epoch 253/500\n","55/55 [==============================] - 114s 2s/step - loss: 0.2519 - dice_coef_loss: 0.2420 - val_loss: 0.2543 - val_dice_coef_loss: 0.2435\n","Epoch 254/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2503 - dice_coef_loss: 0.2409 - val_loss: 0.2627 - val_dice_coef_loss: 0.2509\n","Epoch 255/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2469 - dice_coef_loss: 0.2387 - val_loss: 0.2637 - val_dice_coef_loss: 0.2509\n","Epoch 256/500\n","55/55 [==============================] - 109s 2s/step - loss: 0.2549 - dice_coef_loss: 0.2460 - val_loss: 0.2675 - val_dice_coef_loss: 0.2550\n","Epoch 257/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2557 - dice_coef_loss: 0.2466 - val_loss: 0.2476 - val_dice_coef_loss: 0.2385\n","Epoch 258/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2467 - dice_coef_loss: 0.2376 - val_loss: 0.2562 - val_dice_coef_loss: 0.2453\n","Epoch 259/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2461 - dice_coef_loss: 0.2376 - val_loss: 0.2719 - val_dice_coef_loss: 0.2590\n","Epoch 260/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2571 - dice_coef_loss: 0.2473 - val_loss: 0.2643 - val_dice_coef_loss: 0.2523\n","Epoch 261/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2516 - dice_coef_loss: 0.2418 - val_loss: 0.2621 - val_dice_coef_loss: 0.2499\n","Epoch 262/500\n","55/55 [==============================] - 113s 2s/step - loss: 0.2527 - dice_coef_loss: 0.2431 - val_loss: 0.2520 - val_dice_coef_loss: 0.2415\n","Epoch 263/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2508 - dice_coef_loss: 0.2421 - val_loss: 0.2783 - val_dice_coef_loss: 0.2635\n","Epoch 264/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2629 - dice_coef_loss: 0.2535 - val_loss: 0.2868 - val_dice_coef_loss: 0.2712\n","Epoch 265/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2440 - dice_coef_loss: 0.2349 - val_loss: 0.2754 - val_dice_coef_loss: 0.2615\n","Epoch 266/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2565 - dice_coef_loss: 0.2470 - val_loss: 0.2578 - val_dice_coef_loss: 0.2463\n","Epoch 267/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2542 - dice_coef_loss: 0.2453 - val_loss: 0.2715 - val_dice_coef_loss: 0.2587\n","Epoch 268/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2515 - dice_coef_loss: 0.2430 - val_loss: 0.2731 - val_dice_coef_loss: 0.2591\n","Epoch 269/500\n","55/55 [==============================] - 110s 2s/step - loss: 0.2489 - dice_coef_loss: 0.2398 - val_loss: 0.2464 - val_dice_coef_loss: 0.2372\n","Epoch 270/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2520 - dice_coef_loss: 0.2430 - val_loss: 0.2625 - val_dice_coef_loss: 0.2500\n","Epoch 271/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2470 - dice_coef_loss: 0.2385 - val_loss: 0.2858 - val_dice_coef_loss: 0.2705\n","Epoch 272/500\n","55/55 [==============================] - 98s 2s/step - loss: 0.2558 - dice_coef_loss: 0.2464 - val_loss: 0.2644 - val_dice_coef_loss: 0.2525\n","Epoch 273/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2579 - dice_coef_loss: 0.2492 - val_loss: 0.2773 - val_dice_coef_loss: 0.2632\n","Epoch 274/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2722 - dice_coef_loss: 0.2623 - val_loss: 0.2708 - val_dice_coef_loss: 0.2571\n","Epoch 275/500\n","55/55 [==============================] - 103s 2s/step - loss: 0.2456 - dice_coef_loss: 0.2362 - val_loss: 0.2743 - val_dice_coef_loss: 0.2605\n","Epoch 276/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2476 - dice_coef_loss: 0.2392 - val_loss: 0.2596 - val_dice_coef_loss: 0.2483\n","Epoch 277/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2581 - dice_coef_loss: 0.2480 - val_loss: 0.2611 - val_dice_coef_loss: 0.2493\n","Epoch 278/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2418 - dice_coef_loss: 0.2335 - val_loss: 0.2799 - val_dice_coef_loss: 0.2658\n","Epoch 279/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2559 - dice_coef_loss: 0.2468 - val_loss: 0.2735 - val_dice_coef_loss: 0.2594\n","Epoch 280/500\n","55/55 [==============================] - 101s 2s/step - loss: 0.2495 - dice_coef_loss: 0.2398 - val_loss: 0.2786 - val_dice_coef_loss: 0.2649\n","Epoch 281/500\n","55/55 [==============================] - 104s 2s/step - loss: 0.2582 - dice_coef_loss: 0.2488 - val_loss: 0.2487 - val_dice_coef_loss: 0.2390\n","Epoch 282/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2545 - dice_coef_loss: 0.2455 - val_loss: 0.2679 - val_dice_coef_loss: 0.2547\n","Epoch 283/500\n","55/55 [==============================] - 113s 2s/step - loss: 0.2462 - dice_coef_loss: 0.2368 - val_loss: 0.2612 - val_dice_coef_loss: 0.2497\n","Epoch 284/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2556 - dice_coef_loss: 0.2461 - val_loss: 0.2830 - val_dice_coef_loss: 0.2678\n","Epoch 285/500\n","55/55 [==============================] - 96s 2s/step - loss: 0.2437 - dice_coef_loss: 0.2344 - val_loss: 0.2634 - val_dice_coef_loss: 0.2510\n","Epoch 286/500\n","55/55 [==============================] - 105s 2s/step - loss: 0.2481 - dice_coef_loss: 0.2396 - val_loss: 0.2602 - val_dice_coef_loss: 0.2484\n","Epoch 287/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2500 - dice_coef_loss: 0.2406 - val_loss: 0.2714 - val_dice_coef_loss: 0.2579\n","Epoch 288/500\n","55/55 [==============================] - 102s 2s/step - loss: 0.2528 - dice_coef_loss: 0.2443 - val_loss: 0.2583 - val_dice_coef_loss: 0.2472\n","Epoch 289/500\n","55/55 [==============================] - 106s 2s/step - loss: 0.2480 - dice_coef_loss: 0.2390 - val_loss: 0.2701 - val_dice_coef_loss: 0.2559\n","Epoch 290/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2494 - dice_coef_loss: 0.2407 - val_loss: 0.2610 - val_dice_coef_loss: 0.2492\n","Epoch 291/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2433 - dice_coef_loss: 0.2348 - val_loss: 0.2728 - val_dice_coef_loss: 0.2594\n","Epoch 292/500\n","55/55 [==============================] - 99s 2s/step - loss: 0.2429 - dice_coef_loss: 0.2347 - val_loss: 0.2669 - val_dice_coef_loss: 0.2544\n","Epoch 293/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2505 - dice_coef_loss: 0.2412 - val_loss: 0.2716 - val_dice_coef_loss: 0.2588\n","Epoch 294/500\n","55/55 [==============================] - 107s 2s/step - loss: 0.2508 - dice_coef_loss: 0.2420 - val_loss: 0.2649 - val_dice_coef_loss: 0.2532\n","Epoch 295/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2535 - dice_coef_loss: 0.2444 - val_loss: 0.2837 - val_dice_coef_loss: 0.2696\n","Epoch 296/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2576 - dice_coef_loss: 0.2484 - val_loss: 0.2659 - val_dice_coef_loss: 0.2531\n","Epoch 297/500\n","55/55 [==============================] - 115s 2s/step - loss: 0.2487 - dice_coef_loss: 0.2400 - val_loss: 0.2553 - val_dice_coef_loss: 0.2450\n","Epoch 298/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2483 - dice_coef_loss: 0.2398 - val_loss: 0.2705 - val_dice_coef_loss: 0.2573\n","Epoch 299/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2584 - dice_coef_loss: 0.2489 - val_loss: 0.2729 - val_dice_coef_loss: 0.2592\n","Epoch 300/500\n","55/55 [==============================] - 108s 2s/step - loss: 0.2542 - dice_coef_loss: 0.2457 - val_loss: 0.2642 - val_dice_coef_loss: 0.2527\n","Epoch 301/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2551 - dice_coef_loss: 0.2461 - val_loss: 0.2707 - val_dice_coef_loss: 0.2566\n","Epoch 302/500\n","55/55 [==============================] - 100s 2s/step - loss: 0.2498 - dice_coef_loss: 0.2411 - val_loss: 0.2550 - val_dice_coef_loss: 0.2441\n","Epoch 303/500\n","15/55 [=======>......................] - ETA: 33s - loss: 0.2553 - dice_coef_loss: 0.2457"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MiuXILxJw9e2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPKqGkrkcfWh"},"source":["np.random.randint(100,101)"],"execution_count":null,"outputs":[]}]}